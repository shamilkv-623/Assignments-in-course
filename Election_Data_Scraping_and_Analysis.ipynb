{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Qs/hUaPNDADL6nJX7TKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shamilkv-623/Assignments-in-course/blob/main/Election_Data_Scraping_and_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data scraping"
      ],
      "metadata": {
        "id": "IS_OQdaJRDXY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9PfDyrcSQSBw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urljoin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_and_next_page(response_text:str):\n",
        "    start_idx = response_text.find('const data =') + len('const data =')\n",
        "    end_idx = response_text.rfind(';', start_idx, response_text.find('const next ='))\n",
        "    data_json = response_text[start_idx:end_idx].strip()\n",
        "    data = json.loads(data_json)\n",
        "\n",
        "    start_idx = response_text.find('const next =') + len('const next =')\n",
        "    end_idx = response_text.find(';', start_idx)\n",
        "    next_page = response_text[start_idx:end_idx].strip().strip('\"')\n",
        "\n",
        "    return data, next_page\n",
        "\n",
        "def navigate_next(base_url, next_page):\n",
        "    if next_page != \"null\":\n",
        "        return urljoin(base_url, next_page)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def scrape_data(base_url, state_data):\n",
        "    election_data = {\"ID\": [], \"ST_NAME\": [], \"YEAR\": [], \"AC\": [],\n",
        "                 \"CANDIDATE\": [], \"SEX\": [], \"AGE\": [], \"CATEGORY\": [],\n",
        "                 \"PARTY\": [], \"VOTES\": []}\n",
        "    for entry in state_data:\n",
        "        next = entry['link']\n",
        "        url = urljoin(base_url, next)\n",
        "        while True:\n",
        "            response = requests.get(url)\n",
        "            data, next_page = get_data_and_next_page(response.text)\n",
        "            for row in tqdm(data, desc=f\"Scraping data for year {entry['YEAR']}\"):\n",
        "                for key in election_data.keys():\n",
        "                    election_data[key].append(str(row.get(key, list(row.values())[0])).strip())\n",
        "            url = navigate_next(base_url, next_page)\n",
        "            if not url:\n",
        "                break\n",
        "    return election_data\n",
        "\n",
        "def save(ST_NAME, AC_NAME, election_data):\n",
        "    df = pd.DataFrame(election_data)\n",
        "    df.replace('', np.nan, inplace=True)\n",
        "    df = df.loc[df['VOTES'] != \"None\"]\n",
        "    df['AC'] = df['AC'].str.replace(r'^\\d+\\s+', '', regex=True)\n",
        "    df['AC'] = df['AC'].str.replace(r'[^a-zA-Z\\s\\.]', '', regex=True)\n",
        "    df['CANDIDATE'] = df['CANDIDATE'].str.replace(r'^\\d+\\s+', '', regex=True)\n",
        "    df['CANDIDATE'] = df['CANDIDATE'].str.replace(r'[^a-zA-Z\\s\\.]', '', regex=True)\n",
        "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.drop_duplicates(subset=['ST_NAME', 'YEAR', 'AC', 'CANDIDATE', 'SEX', 'AGE', 'CATEGORY', 'PARTY', 'VOTES'])\n",
        "    df.to_csv(f\"{ST_NAME}.csv\", index=False)\n",
        "    condition = (df[\"AC\"] == AC_NAME)\n",
        "    df = df[condition]\n",
        "    df.to_csv(f\"{ST_NAME}_{AC_NAME}.csv\", index=False)\n",
        "\n",
        "def find_state_data(start_url, ST_NAME):\n",
        "    url = start_url\n",
        "    state_data = []\n",
        "    n_pages = 10\n",
        "    for i in tqdm(range(n_pages), desc=\"Crawling all pages\"):\n",
        "        if url:\n",
        "            response = requests.get(url)\n",
        "            data, next_page = get_data_and_next_page(response.text)\n",
        "            state_data.extend([entry for entry in data if entry['ST_NAME'] == ST_NAME])\n",
        "            url = navigate_next(start_url, next_page)\n",
        "    return state_data\n",
        "\n"
      ],
      "metadata": {
        "id": "4d4V8sOiRJjf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ST_NAME = \"HIMACHAL PRADESH\"\n",
        "AC_NAME = \"RAMPUR\"\n",
        "# saves full state csv and also constituency csv\n",
        "# scraped data undergoes priliminary cleaning as well\n",
        "data = main_scraper(ST_NAME, AC_NAME)"
      ],
      "metadata": {
        "id": "a2ag0vp7S_ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_scraper(ST_NAME, AC_NAME):\n",
        "    start_url = \"https://22f3001919.github.io/tds_project_1/\"\n",
        "    state_data = find_state_data(start_url, ST_NAME)\n",
        "\n",
        "    if not state_data:\n",
        "        print(f\"No data found for state: {ST_NAME}\")\n",
        "        return\n",
        "\n",
        "    election_data = scrape_data(start_url, state_data)\n",
        "    save(ST_NAME, AC_NAME, election_data)\n",
        "    return election_data\n"
      ],
      "metadata": {
        "id": "GX8M-MtzRNsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the given AC_NAME, What percentage of elections did female candidates win, when there was at least one female candidate in that election"
      ],
      "metadata": {
        "id": "AiXhmhjmTUep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "elections_with_female = ac_df.groupby('YEAR').filter(lambda x: (x['SEX'] == 'F').any())\n",
        "winners = elections_with_female.loc[elections_with_female.groupby('YEAR')['VOTES'].idxmax()]\n",
        "total_elections_with_female = winners['YEAR'].nunique()\n",
        "female_wins = winners[winners['SEX'] == 'F']['YEAR'].nunique()\n",
        "if total_elections_with_female == 0:\n",
        "    percentage_female_wins = 0\n",
        "else:\n",
        "  percentage_female_wins = (female_wins / total_elections_with_female) * 100\n",
        "percentage_female_wins"
      ],
      "metadata": {
        "id": "v8XSCfjtTM6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the given AC_NAME, Which election year had the most female candidates contesting an election?"
      ],
      "metadata": {
        "id": "WRjxDnECTjXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "elections_with_female_candidates = ac_df[ac_df[\"SEX\"] == 'F']\n",
        "print(\"List of years sorted in decreasing order of number of female candidates:\")\n",
        "elections_with_female_candidates['YEAR'].value_counts().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "yoRGzi4tTiv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the given AC_NAME, If the second and the third candidate in an election combined their vote, how many elections would they win?"
      ],
      "metadata": {
        "id": "o7dXh5czTv2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "year_counts = ac_df[\"YEAR\"].value_counts()\n",
        "filtered_years = year_counts[year_counts >= 3].index\n",
        "filtered_df = ac_df[ac_df['YEAR'].isin(filtered_years)].sort_values(by=['YEAR', 'VOTES'], ascending=[True, False])\n",
        "second_third_candidates = filtered_df.groupby('YEAR').head(3).groupby('YEAR').tail(2)\n",
        "second_third_combined = second_third_candidates.groupby('YEAR')[\"VOTES\"].sum()\n",
        "winner_count = filtered_df.groupby('YEAR').head(1).groupby('YEAR')[\"VOTES\"].sum()\n",
        "result = (winner_count - second_third_combined) < 0\n",
        "result.sum()"
      ],
      "metadata": {
        "id": "bUEK3JR_TvSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the latest year in which the winner won more than 50 percent of the vote"
      ],
      "metadata": {
        "id": "ubiyGSUST7SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "winners = ac_df.loc[ac_df.groupby('YEAR')['VOTES'].idxmax()].copy()\n",
        "total_votes =  ac_df.groupby('YEAR')['VOTES'].sum().values\n",
        "winners[\"VOTE_SHARE\"] = 100 * ac_df.loc[ac_df.groupby('YEAR')['VOTES'].idxmax()][\"VOTES\"].values / total_votes\n",
        "winners_above_50 = winners[winners[\"VOTE_SHARE\"] > 50]\n",
        "winners_above_50[\"YEAR\"].max()"
      ],
      "metadata": {
        "id": "X9oh-al_TXby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the given AC_NAME, What is the average vote share of the winners across all elections? Give your answer to 2 decimal places"
      ],
      "metadata": {
        "id": "ib6nwv75UCjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "winners = ac_df.loc[ac_df.groupby('YEAR')['VOTES'].idxmax()].copy()\n",
        "total_votes = ac_df.groupby('YEAR')['VOTES'].sum()\n",
        "winners['VOTE_SHARE'] = (100 * winners['VOTES'].values/total_votes).values\n",
        "winners['VOTE_SHARE'].values.mean()"
      ],
      "metadata": {
        "id": "jjEOIRARUBup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the given AC_NAME, In which year was the difference between the first and last candidates votes the biggest"
      ],
      "metadata": {
        "id": "vKiQJytdULRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "df_sorted = ac_df.sort_values(by=['YEAR', 'VOTES'], ascending=[True, False])\n",
        "grouped = df_sorted.groupby('YEAR')\n",
        "def vote_difference(group):\n",
        "    return group.iloc[0]['VOTES'] - group.iloc[-1]['VOTES']\n",
        "\n",
        "differences = grouped.apply(vote_difference)\n",
        "print(\"List of years sorted in decreasing order of difference between first and last candidate:\")\n",
        "differences.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "l1mpAjSTUKl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the highest margin percentage by which the winning candidate has defeated the runner up in any election? Give your answer to 2 decimal places."
      ],
      "metadata": {
        "id": "_NQ5pw4fUOqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_df = pd.read_csv(f\"{ST_NAME}_{AC_NAME}.csv\")\n",
        "winners = ac_df.loc[ac_df.groupby('YEAR')['VOTES'].idxmax()].copy()\n",
        "runner_ups = ac_df.drop(winners.index)\n",
        "runner_ups = ac_df.loc[runner_ups.groupby('YEAR')['VOTES'].idxmax()]\n",
        "total_votes = ac_df.groupby('YEAR')['VOTES'].sum().values\n",
        "winners[\"VOTE_SHARE\"] = 100 * ac_df.loc[ac_df.groupby('YEAR')['VOTES'].idxmax()][\"VOTES\"].values / total_votes\n",
        "runner_ups[\"VOTE_SHARE\"] = 100 * ac_df.loc[runner_ups.groupby('YEAR')['VOTES'].idxmax()][\"VOTES\"].values / total_votes\n",
        "margins = winners[\"VOTE_SHARE\"].values - runner_ups[\"VOTE_SHARE\"].values\n",
        "margins.max()"
      ],
      "metadata": {
        "id": "bHIMFqK-UN57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a given constituency, how many constituencies within the same state are less than 20 kms"
      ],
      "metadata": {
        "id": "-QXRUXm0Ud6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_df = pd.read_csv(f\"{ST_NAME}.csv\")\n",
        "def get_coordinates(state:str, constituency:str):\n",
        "    try:\n",
        "        geolocator = Nominatim(user_agent=\"Mozilla/5.0\")\n",
        "        location = geolocator.geocode(f\"{constituency.lower()}, {state.lower()}, India\")\n",
        "        # print(location)\n",
        "        if location:\n",
        "            return location.latitude, location.longitude\n",
        "        else:\n",
        "            return None, None\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "def calculate_distance(given_coords, lat, lon):\n",
        "    try:\n",
        "        if lat and lon:\n",
        "            return geodesic(given_coords, (lat, lon)).kilometers\n",
        "        else:\n",
        "            return None\n",
        "    except:\n",
        "        return None\n",
        "constituency_list = {place:() for place in state_df[\"AC\"].unique()}\n",
        "estimated_time = 2.8 * len(constituency_list.keys())\n",
        "print(\"Getting latitude and longitude for all constituencies..\")\n",
        "print(f\"Estimated Time:{estimated_time} seconds\")\n",
        "\n",
        "for key in constituency_list.keys():\n",
        "    sleep(2)\n",
        "    constituency_list[key] = get_coordinates(ST_NAME, key)\n",
        "print(\"Done\")\n",
        "temp_df = state_df.copy()\n",
        "temp_df['LAT'], temp_df['LON'] = zip(*state_df.apply(lambda row: constituency_list[row[\"AC\"]], axis=1))\n",
        "given_coords = temp_df.loc[state_df['AC'] == AC_NAME, ['LAT', 'LON']].values[0]\n",
        "temp_df['DISTANCE'] = temp_df.apply(lambda row: calculate_distance(given_coords, row['LAT'], row['LON']), axis=1)\n",
        "nearby_constituencies = temp_df[(temp_df['DISTANCE'] < 20) & (temp_df['AC'] != AC_NAME)]\n",
        "print(\"Count of constituencies within 20 kms:\")\n",
        "nearby_constituencies['AC'].unique().shape"
      ],
      "metadata": {
        "id": "XMQVbrNsUdGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the Pearson correlation coefficient between the votes won by female candidates and male candidates. Only include constituencies and election years that had at least 1 female candidate. Each row in the correlation data table should represent an election."
      ],
      "metadata": {
        "id": "ouMp94NOUyPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_df = pd.read_csv(f\"{ST_NAME}.csv\")\n",
        "df_filtered = state_df.groupby(['YEAR', 'AC']).filter(lambda x: (x['SEX'] == 'F').any())\n",
        "df_female = df_filtered[df_filtered['SEX'] == 'F'][['YEAR', 'VOTES']].rename(columns={'VOTES': 'FEMALE_VOTES'})\n",
        "female_votes_by_year = df_female.groupby('YEAR')['FEMALE_VOTES'].sum()\n",
        "df_male = df_filtered[df_filtered['SEX'] == 'M'][['YEAR', 'VOTES']].rename(columns={'VOTES': 'MALE_VOTES'})\n",
        "male_votes_by_year = df_male.groupby('YEAR')[\"MALE_VOTES\"].sum()\n",
        "male_votes_by_year.corr(female_votes_by_year)"
      ],
      "metadata": {
        "id": "oJw1DRbRUxen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a given state, identify the election year which has the most outliers on the basis of candidate votes. Use the interquartile range (IQR) rule to detect outliers"
      ],
      "metadata": {
        "id": "lX56ttOQU9Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_df = pd.read_csv(f\"{ST_NAME}.csv\")\n",
        "grouped = state_df.groupby('YEAR')\n",
        "Q1 = grouped['VOTES'].transform(lambda x: x.quantile(0.25))\n",
        "Q3 = grouped['VOTES'].transform(lambda x: x.quantile(0.75))\n",
        "IQR = Q3 - Q1\n",
        "lb = Q1 - 1.5 * IQR\n",
        "ub = Q3 + 1.5 * IQR\n",
        "condition = (state_df['VOTES'] < lb) | (state_df['VOTES'] > ub)\n",
        "print(\"List of years sorted in descending order of number of outliers:\")\n",
        "state_df[condition][\"YEAR\"].value_counts()"
      ],
      "metadata": {
        "id": "YwJ1eM1NU8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30HLSi8iUo1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}